{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cafb145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score: 79\n",
      "Negative Score: 24\n",
      "Polarity Score: 0.5339805773399944\n",
      "Subjectivity Score: 0.09932497579621506\n",
      "\n",
      "Readability Analysis:\n",
      "Average Sentence Length: 23.15\n",
      "Percentage of Complex Words: 0.13930885529157666\n",
      "Fog Index: 9.315723542116631\n",
      "Average Number of Words Per Sentence: 23.15\n",
      "Complex Word Count: 258\n",
      "\n",
      "Additional Analysis:\n",
      "Total Syllable Count: Skipped\n",
      "Personal Pronouns Count: 2\n",
      "Average Word Length: 6.668273866923819\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def load_stopwords(stopwords_folder):\n",
    "    stop_words = set()\n",
    "    for file in os.listdir(stopwords_folder):\n",
    "        with open(os.path.join(stopwords_folder, file), 'r') as f:\n",
    "            words = f.read().splitlines()\n",
    "            stop_words.update(words)\n",
    "    return stop_words\n",
    "\n",
    "def clean_text(text, stopwords):\n",
    "    words = word_tokenize(text)\n",
    "    cleaned_words = [word.lower() for word in words if word.lower() not in stopwords]\n",
    "    return cleaned_words\n",
    "\n",
    "def create_dictionary(master_dict, stopwords):\n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    "    \n",
    "    with open(os.path.join(master_dict, 'positive-words.txt'), 'r') as pos_file:\n",
    "        pos_words = [word.strip() for word in pos_file if word.strip() not in stopwords]\n",
    "\n",
    "    with open(os.path.join(master_dict, 'negative-words.txt'), 'r') as neg_file:\n",
    "        neg_words = [word.strip() for word in neg_file if word.strip() not in stopwords]\n",
    "\n",
    "    return pos_words, neg_words\n",
    "\n",
    "def calculate_scores(cleaned_text, pos_words, neg_words):\n",
    "    positive_score = sum(1 for word in cleaned_text if word in pos_words)\n",
    "    negative_score = sum(1 for word in cleaned_text if word in neg_words)\n",
    "    \n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score )+ 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score) / (len(cleaned_text) + 0.000001)\n",
    "    \n",
    "    return positive_score, negative_score, polarity_score, subjectivity_score\n",
    "\n",
    "def calculate_readability(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Average Sentence Length\n",
    "    avg_sentence_length = len(words) / len(sentences)\n",
    "    \n",
    "    # Complex Word Count\n",
    "    d = cmudict.dict()\n",
    "    complex_words = [word for word in words if word.lower() in d and len(d[word.lower()]) > 2]\n",
    "    \n",
    "    # Percentage of Complex words\n",
    "    percentage_complex_words = len(complex_words) / len(words)\n",
    "    \n",
    "    # Fog Index\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    \n",
    "    # Average Number of Words Per Sentence\n",
    "    avg_words_per_sentence = len(words) / len(sentences)\n",
    "    \n",
    "    return avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, len(complex_words)\n",
    "\n",
    "\"\"\"\n",
    "def count_syllables(word):\n",
    "    d = cmudict.dict()\n",
    "    word = word.lower()\n",
    "    if word in d:\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word]][0]\n",
    "    # Handling words ending with \"es\" and \"ed\"\n",
    "    if word.endswith('es') or word.endswith('ed'):\n",
    "        return count_syllables(word[:-2])\n",
    "    # Words that are not found in the CMU dictionary\n",
    "    return max(1, len(re.findall(r'[aeiouy]+', word)))\n",
    "\n",
    "def calculate_syllable_count(cleaned_text):\n",
    "    syllable_count = sum(count_syllables(word) for word in cleaned_text)\n",
    "    return syllable_count\n",
    "\"\"\"\n",
    "def count_personal_pronouns(text):\n",
    "    personal_pronouns = re.findall(r'\\b(?:I|we|my|ours|us)\\b', text, flags=re.IGNORECASE)\n",
    "    return len(personal_pronouns)\n",
    "\n",
    "def calculate_average_word_length(cleaned_text):\n",
    "    total_chars = sum(len(word) for word in cleaned_text)\n",
    "    avg_word_length = total_chars / len(cleaned_text)\n",
    "    return avg_word_length\n",
    "\n",
    "# Example usage\n",
    "stopwords_folder = \"StopWords\"\n",
    "master_dict_folder = \"MasterDictionary\" \n",
    "text_file = \"txt/123.txt\" \n",
    "\n",
    "with open(text_file, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "stopwords = load_stopwords(stopwords_folder)\n",
    "cleaned_text = clean_text(text, stopwords)\n",
    "positive_words, negative_words = create_dictionary(master_dict_folder, stopwords)\n",
    "pos_score, neg_score, polarity, subjectivity = calculate_scores(cleaned_text, positive_words, negative_words)\n",
    "\n",
    "avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, complex_word_count = calculate_readability(text)\n",
    "#syllable_count = calculate_syllable_count(cleaned_text)\n",
    "personal_pronouns_count = count_personal_pronouns(text)\n",
    "average_word_length = calculate_average_word_length(cleaned_text)\n",
    "\n",
    "print(\"Positive Score:\", pos_score)\n",
    "print(\"Negative Score:\", neg_score)\n",
    "print(\"Polarity Score:\", polarity)\n",
    "print(\"Subjectivity Score:\", subjectivity)\n",
    "\n",
    "print(\"\\nReadability Analysis:\")\n",
    "print(f\"Average Sentence Length: {avg_sentence_length}\")\n",
    "print(f\"Percentage of Complex Words: {percentage_complex_words}\")\n",
    "print(f\"Fog Index: {fog_index}\")\n",
    "print(f\"Average Number of Words Per Sentence: {avg_words_per_sentence}\")\n",
    "print(f\"Complex Word Count: {complex_word_count}\")\n",
    "\n",
    "print(\"\\nAdditional Analysis:\")\n",
    "#print(f\"Total Syllable Count: {syllable_count}\")\n",
    "print(\"Total Syllable Count: Skipped\")\n",
    "print(f\"Personal Pronouns Count: {personal_pronouns_count}\")\n",
    "print(f\"Average Word Length: {average_word_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267702b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15a98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68dbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e8a6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def load_stopwords(stopwords_folder):\n",
    "    stop_words = set()\n",
    "    for file in os.listdir(stopwords_folder):\n",
    "        with open(os.path.join(stopwords_folder, file), 'r') as f:\n",
    "            words = f.read().splitlines()\n",
    "            stop_words.update(words)\n",
    "    return stop_words\n",
    "\n",
    "def clean_text(text, stopwords):\n",
    "    words = word_tokenize(text)\n",
    "    cleaned_words = [word.lower() for word in words if word.lower() not in stopwords]\n",
    "    return cleaned_words\n",
    "\n",
    "def create_dictionary(master_dict, stopwords):\n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    "    \n",
    "    with open(os.path.join(master_dict, 'positive-words.txt'), 'r') as pos_file:\n",
    "        pos_words = [word.strip() for word in pos_file if word.strip() not in stopwords]\n",
    "\n",
    "    with open(os.path.join(master_dict, 'negative-words.txt'), 'r') as neg_file:\n",
    "        neg_words = [word.strip() for word in neg_file if word.strip() not in stopwords]\n",
    "\n",
    "    return pos_words, neg_words\n",
    "\n",
    "def calculate_scores(cleaned_text, pos_words, neg_words):\n",
    "    positive_score = sum(1 for word in cleaned_text if word in pos_words)\n",
    "    negative_score = sum(1 for word in cleaned_text if word in neg_words)\n",
    "    \n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score )+ 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score) / (len(cleaned_text) + 0.000001)\n",
    "    \n",
    "    return positive_score, negative_score, polarity_score, subjectivity_score\n",
    "\n",
    "def calculate_readability(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Average Sentence Length\n",
    "    avg_sentence_length = len(words) / len(sentences)\n",
    "    \n",
    "    # Complex Word Count\n",
    "    d = cmudict.dict()\n",
    "    complex_words = [word for word in words if word.lower() in d and len(d[word.lower()]) > 2]\n",
    "    \n",
    "    # Percentage of Complex words\n",
    "    percentage_complex_words = len(complex_words) / len(words)\n",
    "    \n",
    "    # Fog Index\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    \n",
    "    # Average Number of Words Per Sentence\n",
    "    avg_words_per_sentence = len(words) / len(sentences)\n",
    "    \n",
    "    return avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, len(complex_words)\n",
    "\n",
    "\"\"\"\n",
    "def count_syllables(word):\n",
    "    d = cmudict.dict()\n",
    "    word = word.lower()\n",
    "    if word in d:\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word]][0]\n",
    "    # Handling words ending with \"es\" and \"ed\"\n",
    "    if word.endswith('es') or word.endswith('ed'):\n",
    "        return count_syllables(word[:-2])\n",
    "    # Words that are not found in the CMU dictionary\n",
    "    return max(1, len(re.findall(r'[aeiouy]+', word)))\n",
    "\n",
    "def calculate_syllable_count(cleaned_text):\n",
    "    syllable_count = sum(count_syllables(word) for word in cleaned_text)\n",
    "    return syllable_count\n",
    "\"\"\"\n",
    "def count_personal_pronouns(text):\n",
    "    personal_pronouns = re.findall(r'\\b(?:I|we|my|ours|and|us)\\b', text, flags=re.IGNORECASE)\n",
    "    return len(personal_pronouns)\n",
    "\n",
    "def calculate_average_word_length(cleaned_text):\n",
    "    total_chars = sum(len(word) for word in cleaned_text)\n",
    "    avg_word_length = total_chars / len(cleaned_text)\n",
    "    return avg_word_length\n",
    "\n",
    "# Example usage\n",
    "def process_text_files_in_folder(folder_path):\n",
    "    stopwords_folder = \"StopWords\"\n",
    "    master_dict_folder = \"MasterDictionary\"\n",
    "\n",
    "    stopwords = load_stopwords(stopwords_folder)\n",
    "    positive_words, negative_words = create_dictionary(master_dict_folder, stopwords)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "\n",
    "            cleaned_text = clean_text(text, stopwords)\n",
    "            pos_score, neg_score, polarity, subjectivity = calculate_scores(cleaned_text, positive_words, negative_words)\n",
    "\n",
    "            avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, complex_word_count = calculate_readability(text)\n",
    "            personal_pronouns_count = count_personal_pronouns(text)\n",
    "            average_word_length = calculate_average_word_length(cleaned_text)\n",
    "\n",
    "            # Store the results in a dictionary for each file\n",
    "            result = {\n",
    "                'URL_ID': file_name[: -len(\".txt\")],\n",
    "                'POSITIVE SCORE': pos_score,\n",
    "                'NEGATIVE SCORE': neg_score,\n",
    "                'POLARITY SCORE': polarity,\n",
    "                'SUBJECTIVITY SCORE': subjectivity,\n",
    "                'AVG SENTENCE LENGTH': avg_sentence_length,\n",
    "                'PERCENTAGE OF COMPLEX WORDS': percentage_complex_words,\n",
    "                'FOG INDEX': fog_index,\n",
    "                'AVG NUMBER OF WORDS PER SENTENCE': avg_words_per_sentence,\n",
    "                'COMPLEX WORD COUNT': complex_word_count,\n",
    "                'WORD COUNT': \"\",\n",
    "                'SYLLABLE PER WORD':\"\",\n",
    "                'PERSONAL PRONOUNS': personal_pronouns_count,\n",
    "                'AVG WORD LENGTH': average_word_length\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c05cb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  URL_ID  POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
      "0    123              80              24        0.538462            0.099808   \n",
      "1   2345              38              13        0.490196            0.147399   \n",
      "2    321              38              13        0.490196            0.147399   \n",
      "3    432              35              27        0.129032            0.077792   \n",
      "\n",
      "   AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
      "0            23.250000                     0.138710   9.355484   \n",
      "1            27.040000                     0.125740  10.866296   \n",
      "2            27.040000                     0.125740  10.866296   \n",
      "3            23.066667                     0.108382   9.270019   \n",
      "\n",
      "   AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT WORD COUNT  \\\n",
      "0                         23.250000                 258              \n",
      "1                         27.040000                  85              \n",
      "2                         27.040000                  85              \n",
      "3                         23.066667                 150              \n",
      "\n",
      "  SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
      "0                                   63         6.623800  \n",
      "1                                   37         6.982659  \n",
      "2                                   37         6.982659  \n",
      "3                                   63         6.350063  \n"
     ]
    }
   ],
   "source": [
    "# Example usage for processing a folder of text files\n",
    "folder_path = \"txt\"\n",
    "results = process_text_files_in_folder(folder_path)\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "df = pd.DataFrame(results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc7fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"coffe.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c2c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
