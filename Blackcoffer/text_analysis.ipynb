{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8a6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import cmudict,stopwords\n",
    "import re\n",
    "import pandas as pd\n",
    "# Download the NLTK resources if you haven't already\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "\n",
    "def load_stopwords(stopwords_folder):\n",
    "    stop_words = set()\n",
    "    for file in os.listdir(stopwords_folder):\n",
    "        with open(os.path.join(stopwords_folder, file), 'r') as f:\n",
    "            words = f.read().splitlines()\n",
    "            stop_words.update(words)\n",
    "    return stop_words\n",
    "\n",
    "def clean_text(text, stopwords):\n",
    "    words = word_tokenize(text)\n",
    "    cleaned_words = [word.lower() for word in words if word.lower() not in stopwords]\n",
    "    return cleaned_words\n",
    "\n",
    "def create_dictionary(master_dict, stopwords):\n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    "    \n",
    "    with open(os.path.join(master_dict, 'positive-words.txt'), 'r') as pos_file:\n",
    "        pos_words = [word.strip() for word in pos_file if word.strip() not in stopwords]\n",
    "\n",
    "    with open(os.path.join(master_dict, 'negative-words.txt'), 'r') as neg_file:\n",
    "        neg_words = [word.strip() for word in neg_file if word.strip() not in stopwords]\n",
    "\n",
    "    return pos_words, neg_words\n",
    "\n",
    "def calculate_scores(cleaned_text, pos_words, neg_words):\n",
    "    positive_score = sum(1 for word in cleaned_text if word in pos_words)\n",
    "    negative_score = sum(1 for word in cleaned_text if word in neg_words)\n",
    "    \n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score )+ 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score) / (len(cleaned_text) + 0.000001)\n",
    "    \n",
    "    return positive_score, negative_score, polarity_score, subjectivity_score\n",
    "\n",
    "def calculate_readability(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Average Sentence Length\n",
    "    avg_sentence_length = len(words) / len(sentences)\n",
    "    \n",
    "    # Complex Word Count\n",
    "    d = cmudict.dict()\n",
    "    complex_words = [word for word in words if word.lower() in d and len(d[word.lower()]) > 2]\n",
    "    \n",
    "    # Percentage of Complex words\n",
    "    percentage_complex_words = len(complex_words) / len(words)\n",
    "    \n",
    "    # Fog Index\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    \n",
    "    # Average Number of Words Per Sentence\n",
    "    avg_words_per_sentence = len(words) / len(sentences)\n",
    "    \n",
    "    return avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, len(complex_words)\n",
    "\n",
    "def count_words(text):\n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Calculate word count\n",
    "    word_count = len(words)\n",
    "\n",
    "    # Calculate syllable count per word\n",
    "    def count_syllables(word):\n",
    "        vowels = 'aeiouy'\n",
    "        count = 0\n",
    "        word = word.lower()\n",
    "        if word.endswith(('es', 'ed')):\n",
    "            return 0  # exceptions for words ending with \"es\" or \"ed\"\n",
    "        if word[0] in vowels:\n",
    "            count += 1\n",
    "        for index in range(1, len(word)):\n",
    "            if word[index] in vowels and word[index - 1] not in vowels:\n",
    "                count += 1\n",
    "        if word.endswith('e'):\n",
    "            count -= 1  # excluding words ending with 'e'\n",
    "        if count == 0:\n",
    "            count = 1  # each word should have at least one syllable\n",
    "        return count\n",
    "\n",
    "    syllable_count_per_word = [count_syllables(word) for word in words]\n",
    "\n",
    "    return word_count, syllable_count_per_word\n",
    "\n",
    "def count_personal_pronouns(text):\n",
    "    personal_pronouns = re.findall(r'\\b(?:I|we|my|ours|and|us)\\b', text, flags=re.IGNORECASE)\n",
    "    return len(personal_pronouns)\n",
    "\n",
    "def calculate_average_word_length(cleaned_text):\n",
    "    total_chars = sum(len(word) for word in cleaned_text)\n",
    "    avg_word_length = total_chars / len(cleaned_text)\n",
    "    return avg_word_length\n",
    "\n",
    "# Example usage\n",
    "def process_text_files_in_folder(folder_path):\n",
    "    stopwords_folder = \"StopWords\"\n",
    "    master_dict_folder = \"MasterDictionary\"\n",
    "\n",
    "    stopwords = load_stopwords(stopwords_folder)\n",
    "    positive_words, negative_words = create_dictionary(master_dict_folder, stopwords)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "\n",
    "            cleaned_text = clean_text(text, stopwords)\n",
    "            pos_score, neg_score, polarity, subjectivity = calculate_scores(cleaned_text, positive_words, negative_words)\n",
    "\n",
    "            avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, complex_word_count = calculate_readability(text)\n",
    "            personal_pronouns_count = count_personal_pronouns(text)\n",
    "            word_count, syllable_count_per_word = count_words(text)\n",
    "            avg_syllable_count = sum(syllable_count_per_word) / word_count if word_count > 0 else 0\n",
    "            average_word_length = calculate_average_word_length(cleaned_text)\n",
    "\n",
    "            # Store the results in a dictionary for each file\n",
    "            result = {\n",
    "                'URL_ID': file_name[: -len(\".txt\")],\n",
    "                'POSITIVE SCORE': pos_score,\n",
    "                'NEGATIVE SCORE': neg_score,\n",
    "                'POLARITY SCORE': polarity,\n",
    "                'SUBJECTIVITY SCORE': subjectivity,\n",
    "                'AVG SENTENCE LENGTH': avg_sentence_length,\n",
    "                'PERCENTAGE OF COMPLEX WORDS': percentage_complex_words,\n",
    "                'FOG INDEX': fog_index,\n",
    "                'AVG NUMBER OF WORDS PER SENTENCE': avg_words_per_sentence,\n",
    "                'COMPLEX WORD COUNT': complex_word_count,\n",
    "                'WORD COUNT': word_count,\n",
    "                'SYLLABLE PER WORD':avg_syllable_count,\n",
    "                'PERSONAL PRONOUNS': personal_pronouns_count,\n",
    "                'AVG WORD LENGTH': average_word_length\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c05cb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      URL_ID  POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  \\\n",
      "0    10282.6              61              25        0.418605   \n",
      "1    10744.4              46              23        0.333333   \n",
      "2    11206.2              27              12        0.384615   \n",
      "3      11668              27              12        0.384615   \n",
      "4    12129.8              38              13        0.490196   \n",
      "..       ...             ...             ...             ...   \n",
      "109   7973.6              35              26        0.147541   \n",
      "110   8435.4              35              26        0.147541   \n",
      "111   8897.2              60              38        0.224490   \n",
      "112     9359              66              38        0.269231   \n",
      "113   9820.8              70              28        0.428571   \n",
      "\n",
      "     SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  \\\n",
      "0              0.081285            24.850000                     0.093561   \n",
      "1              0.088348            23.107692                     0.098535   \n",
      "2              0.083871            18.500000                     0.088132   \n",
      "3              0.083871            18.500000                     0.088132   \n",
      "4              0.117783            22.405405                     0.090470   \n",
      "..                  ...                  ...                          ...   \n",
      "109            0.085196            31.725000                     0.099291   \n",
      "110            0.085196            31.725000                     0.099291   \n",
      "111            0.117506            20.395062                     0.121065   \n",
      "112            0.095764            22.418605                     0.120332   \n",
      "113            0.108168            19.197917                     0.106891   \n",
      "\n",
      "     FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  \\\n",
      "0     9.977425                         24.850000                 186   \n",
      "1     9.282491                         23.107692                 148   \n",
      "2     7.435253                         18.500000                  75   \n",
      "3     7.435253                         18.500000                  75   \n",
      "4     8.998350                         22.405405                  75   \n",
      "..         ...                               ...                 ...   \n",
      "109  12.729716                         31.725000                 126   \n",
      "110  12.729716                         31.725000                 126   \n",
      "111   8.206451                         20.395062                 200   \n",
      "112   9.015575                         22.418605                 232   \n",
      "113   7.721923                         19.197917                 197   \n",
      "\n",
      "     WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
      "0           937           1.913554                 80         5.860113  \n",
      "1           686           1.858601                 61         5.653009  \n",
      "2           399           1.751880                 36         5.630108  \n",
      "3           399           1.751880                 36         5.630108  \n",
      "4           394           1.677665                 24         5.584296  \n",
      "..          ...                ...                ...              ...  \n",
      "109         584           1.970890                 54         6.131285  \n",
      "110         584           1.970890                 54         6.131285  \n",
      "111         734           1.711172                 65         5.339329  \n",
      "112         993           1.977845                 65         6.269797  \n",
      "113         886           1.869074                 57         5.589404  \n",
      "\n",
      "[114 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage for processing a folder of text files\n",
    "folder_path = \"txt\"\n",
    "results = process_text_files_in_folder(folder_path)\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "df = pd.DataFrame(results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc7fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"coffer.xlsx\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c2c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
