{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cafb145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score: 79\n",
      "Negative Score: 24\n",
      "Polarity Score: 0.5339805773399944\n",
      "Subjectivity Score: 0.09932497579621506\n",
      "\n",
      "Readability Analysis:\n",
      "Average Sentence Length: 23.15\n",
      "Percentage of Complex Words: 0.13930885529157666\n",
      "Fog Index: 9.315723542116631\n",
      "Average Number of Words Per Sentence: 23.15\n",
      "Complex Word Count: 258\n",
      "\n",
      "Additional Analysis:\n",
      "Total Syllable Count: Skipped\n",
      "Personal Pronouns Count: 2\n",
      "Average Word Length: 6.668273866923819\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def load_stopwords(stopwords_folder):\n",
    "    stop_words = set()\n",
    "    for file in os.listdir(stopwords_folder):\n",
    "        with open(os.path.join(stopwords_folder, file), 'r') as f:\n",
    "            words = f.read().splitlines()\n",
    "            stop_words.update(words)\n",
    "    return stop_words\n",
    "\n",
    "def clean_text(text, stopwords):\n",
    "    words = word_tokenize(text)\n",
    "    cleaned_words = [word.lower() for word in words if word.lower() not in stopwords]\n",
    "    return cleaned_words\n",
    "\n",
    "def create_dictionary(master_dict, stopwords):\n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    "    \n",
    "    with open(os.path.join(master_dict, 'positive-words.txt'), 'r') as pos_file:\n",
    "        pos_words = [word.strip() for word in pos_file if word.strip() not in stopwords]\n",
    "\n",
    "    with open(os.path.join(master_dict, 'negative-words.txt'), 'r') as neg_file:\n",
    "        neg_words = [word.strip() for word in neg_file if word.strip() not in stopwords]\n",
    "\n",
    "    return pos_words, neg_words\n",
    "\n",
    "def calculate_scores(cleaned_text, pos_words, neg_words):\n",
    "    positive_score = sum(1 for word in cleaned_text if word in pos_words)\n",
    "    negative_score = sum(1 for word in cleaned_text if word in neg_words)\n",
    "    \n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score )+ 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score) / (len(cleaned_text) + 0.000001)\n",
    "    \n",
    "    return positive_score, negative_score, polarity_score, subjectivity_score\n",
    "\n",
    "def calculate_readability(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Average Sentence Length\n",
    "    avg_sentence_length = len(words) / len(sentences)\n",
    "    \n",
    "    # Complex Word Count\n",
    "    d = cmudict.dict()\n",
    "    complex_words = [word for word in words if word.lower() in d and len(d[word.lower()]) > 2]\n",
    "    \n",
    "    # Percentage of Complex words\n",
    "    percentage_complex_words = len(complex_words) / len(words)\n",
    "    \n",
    "    # Fog Index\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    \n",
    "    # Average Number of Words Per Sentence\n",
    "    avg_words_per_sentence = len(words) / len(sentences)\n",
    "    \n",
    "    return avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, len(complex_words)\n",
    "\n",
    "\"\"\"\n",
    "def count_syllables(word):\n",
    "    d = cmudict.dict()\n",
    "    word = word.lower()\n",
    "    if word in d:\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word]][0]\n",
    "    # Handling words ending with \"es\" and \"ed\"\n",
    "    if word.endswith('es') or word.endswith('ed'):\n",
    "        return count_syllables(word[:-2])\n",
    "    # Words that are not found in the CMU dictionary\n",
    "    return max(1, len(re.findall(r'[aeiouy]+', word)))\n",
    "\n",
    "def calculate_syllable_count(cleaned_text):\n",
    "    syllable_count = sum(count_syllables(word) for word in cleaned_text)\n",
    "    return syllable_count\n",
    "\"\"\"\n",
    "def count_personal_pronouns(text):\n",
    "    personal_pronouns = re.findall(r'\\b(?:I|we|my|ours|us)\\b', text, flags=re.IGNORECASE)\n",
    "    return len(personal_pronouns)\n",
    "\n",
    "def calculate_average_word_length(cleaned_text):\n",
    "    total_chars = sum(len(word) for word in cleaned_text)\n",
    "    avg_word_length = total_chars / len(cleaned_text)\n",
    "    return avg_word_length\n",
    "\n",
    "# Example usage\n",
    "stopwords_folder = \"StopWords\"\n",
    "master_dict_folder = \"MasterDictionary\" \n",
    "text_file = \"txt/123.txt\" \n",
    "\n",
    "with open(text_file, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "stopwords = load_stopwords(stopwords_folder)\n",
    "cleaned_text = clean_text(text, stopwords)\n",
    "positive_words, negative_words = create_dictionary(master_dict_folder, stopwords)\n",
    "pos_score, neg_score, polarity, subjectivity = calculate_scores(cleaned_text, positive_words, negative_words)\n",
    "\n",
    "avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, complex_word_count = calculate_readability(text)\n",
    "#syllable_count = calculate_syllable_count(cleaned_text)\n",
    "personal_pronouns_count = count_personal_pronouns(text)\n",
    "average_word_length = calculate_average_word_length(cleaned_text)\n",
    "\n",
    "print(\"Positive Score:\", pos_score)\n",
    "print(\"Negative Score:\", neg_score)\n",
    "print(\"Polarity Score:\", polarity)\n",
    "print(\"Subjectivity Score:\", subjectivity)\n",
    "\n",
    "print(\"\\nReadability Analysis:\")\n",
    "print(f\"Average Sentence Length: {avg_sentence_length}\")\n",
    "print(f\"Percentage of Complex Words: {percentage_complex_words}\")\n",
    "print(f\"Fog Index: {fog_index}\")\n",
    "print(f\"Average Number of Words Per Sentence: {avg_words_per_sentence}\")\n",
    "print(f\"Complex Word Count: {complex_word_count}\")\n",
    "\n",
    "print(\"\\nAdditional Analysis:\")\n",
    "#print(f\"Total Syllable Count: {syllable_count}\")\n",
    "print(\"Total Syllable Count: Skipped\")\n",
    "print(f\"Personal Pronouns Count: {personal_pronouns_count}\")\n",
    "print(f\"Average Word Length: {average_word_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b267702b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score: 79\n",
      "Negative Score: 24\n",
      "Polarity Score: 0.5339805773399944\n",
      "Subjectivity Score: 0.09932497579621506\n",
      "\n",
      "Readability Analysis:\n",
      "Average Sentence Length: 23.15\n",
      "Percentage of Complex Words: 0.13930885529157666\n",
      "Fog Index: 9.315723542116631\n",
      "Average Number of Words Per Sentence: 23.15\n",
      "Complex Word Count: 258\n",
      "\n",
      "Additional Analysis:\n",
      "Total Syllable Count: Skipped\n",
      "Personal Pronouns Count: 2\n",
      "Average Word Length: 6.668273866923819\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def load_stopwords(stopwords_folder):\n",
    "    stop_words = set()\n",
    "    for file in os.listdir(stopwords_folder):\n",
    "        with open(os.path.join(stopwords_folder, file), 'r') as f:\n",
    "            words = f.read().splitlines()\n",
    "            stop_words.update(words)\n",
    "    return stop_words\n",
    "\n",
    "def clean_text(text, stopwords):\n",
    "    words = word_tokenize(text)\n",
    "    cleaned_words = [word.lower() for word in words if word.lower() not in stopwords]\n",
    "    return cleaned_words\n",
    "\n",
    "def create_dictionary(master_dict, stopwords):\n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    "    \n",
    "    with open(os.path.join(master_dict, 'positive-words.txt'), 'r') as pos_file:\n",
    "        pos_words = [word.strip() for word in pos_file if word.strip() not in stopwords]\n",
    "\n",
    "    with open(os.path.join(master_dict, 'negative-words.txt'), 'r') as neg_file:\n",
    "        neg_words = [word.strip() for word in neg_file if word.strip() not in stopwords]\n",
    "\n",
    "    return pos_words, neg_words\n",
    "\n",
    "def calculate_scores(cleaned_text, pos_words, neg_words):\n",
    "    positive_score = sum(1 for word in cleaned_text if word in pos_words)\n",
    "    negative_score = sum(1 for word in cleaned_text if word in neg_words)\n",
    "    \n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score )+ 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score) / (len(cleaned_text) + 0.000001)\n",
    "    \n",
    "    return positive_score, negative_score, polarity_score, subjectivity_score\n",
    "\n",
    "def calculate_readability(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Average Sentence Length\n",
    "    avg_sentence_length = len(words) / len(sentences)\n",
    "    \n",
    "    # Complex Word Count\n",
    "    d = cmudict.dict()\n",
    "    complex_words = [word for word in words if word.lower() in d and len(d[word.lower()]) > 2]\n",
    "    \n",
    "    # Percentage of Complex words\n",
    "    percentage_complex_words = len(complex_words) / len(words)\n",
    "    \n",
    "    # Fog Index\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    \n",
    "    # Average Number of Words Per Sentence\n",
    "    avg_words_per_sentence = len(words) / len(sentences)\n",
    "    \n",
    "    return avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, len(complex_words)\n",
    "\n",
    "\"\"\"\n",
    "def count_syllables(word):\n",
    "    d = cmudict.dict()\n",
    "    word = word.lower()\n",
    "    if word in d:\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word]][0]\n",
    "    # Handling words ending with \"es\" and \"ed\"\n",
    "    if word.endswith('es') or word.endswith('ed'):\n",
    "        return count_syllables(word[:-2])\n",
    "    # Words that are not found in the CMU dictionary\n",
    "    return max(1, len(re.findall(r'[aeiouy]+', word)))\n",
    "\n",
    "def calculate_syllable_count(cleaned_text):\n",
    "    syllable_count = sum(count_syllables(word) for word in cleaned_text)\n",
    "    return syllable_count\n",
    "\"\"\"\n",
    "def count_personal_pronouns(text):\n",
    "    personal_pronouns = re.findall(r'\\b(?:I|we|my|ours|us)\\b', text, flags=re.IGNORECASE)\n",
    "    return len(personal_pronouns)\n",
    "\n",
    "def calculate_average_word_length(cleaned_text):\n",
    "    total_chars = sum(len(word) for word in cleaned_text)\n",
    "    avg_word_length = total_chars / len(cleaned_text)\n",
    "    return avg_word_length\n",
    "\n",
    "# Example usage\n",
    "stopwords_folder = \"StopWords\"\n",
    "master_dict_folder = \"MasterDictionary\" \n",
    "text_file = \"txt/123.txt\" \n",
    "\n",
    "with open(text_file, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "stopwords = load_stopwords(stopwords_folder)\n",
    "cleaned_text = clean_text(text, stopwords)\n",
    "positive_words, negative_words = create_dictionary(master_dict_folder, stopwords)\n",
    "pos_score, neg_score, polarity, subjectivity = calculate_scores(cleaned_text, positive_words, negative_words)\n",
    "\n",
    "avg_sentence_length, percentage_complex_words, fog_index, avg_words_per_sentence, complex_word_count = calculate_readability(text)\n",
    "#syllable_count = calculate_syllable_count(cleaned_text)\n",
    "personal_pronouns_count = count_personal_pronouns(text)\n",
    "average_word_length = calculate_average_word_length(cleaned_text)\n",
    "\n",
    "print(\"Positive Score:\", pos_score)\n",
    "print(\"Negative Score:\", neg_score)\n",
    "print(\"Polarity Score:\", polarity)\n",
    "print(\"Subjectivity Score:\", subjectivity)\n",
    "\n",
    "print(\"\\nReadability Analysis:\")\n",
    "print(f\"Average Sentence Length: {avg_sentence_length}\")\n",
    "print(f\"Percentage of Complex Words: {percentage_complex_words}\")\n",
    "print(f\"Fog Index: {fog_index}\")\n",
    "print(f\"Average Number of Words Per Sentence: {avg_words_per_sentence}\")\n",
    "print(f\"Complex Word Count: {complex_word_count}\")\n",
    "\n",
    "print(\"\\nAdditional Analysis:\")\n",
    "#print(f\"Total Syllable Count: {syllable_count}\")\n",
    "print(\"Total Syllable Count: Skipped\")\n",
    "print(f\"Personal Pronouns Count: {personal_pronouns_count}\")\n",
    "print(f\"Average Word Length: {average_word_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7d6444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"POSITIVE SCORE\":[], \"NEGATIVE SCORE\":[], \"POLARITY SCORE\":[], \"SUBJECTIVITY SCORE\":[], \"AVG SENTENCE LENGTH\":[], \"PERCENTAGE OF COMPLEX WORDS\":[], \"FOG INDEX\":[], \"AVG NUMBER OF WORDS PER SENTENCE\":[], \"COMPLEX WORD COUNT\":[], \"WORD COUNT\":[], \"SYLLABLE PER WORD\":[], \"PERSONAL PRONOUNS\":[], \"AVG WORD LENGTH\":[]}\n",
    "\n",
    "d['POSITIVE SCORE'].append(1)\n",
    "#d\n",
    "\n",
    "values_count = len(d['POSITIVE SCORE'])\n",
    "keys = d.keys()\n",
    "for key in keys:\n",
    "    while len(d[key]) < values_count:\n",
    "        d[key].append(None) \n",
    "        \n",
    "coffe_df = pd.DataFrame.from_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc38106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POSITIVE SCORE NEGATIVE SCORE POLARITY SCORE SUBJECTIVITY SCORE  \\\n",
       "0               1           None           None               None   \n",
       "\n",
       "  AVG SENTENCE LENGTH PERCENTAGE OF COMPLEX WORDS FOG INDEX  \\\n",
       "0                None                        None      None   \n",
       "\n",
       "  AVG NUMBER OF WORDS PER SENTENCE COMPLEX WORD COUNT WORD COUNT  \\\n",
       "0                             None               None       None   \n",
       "\n",
       "  SYLLABLE PER WORD PERSONAL PRONOUNS AVG WORD LENGTH  \n",
       "0              None              None            None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce6289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
